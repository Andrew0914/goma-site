export const metadata = {
  title: "Los 4 pilares de una buena prueba unitaria",
  description: "Una prueba unitaria, tiene como pilares o fundamentos lo siguiente:, Protecci√≥n contra las regresiones, Resistencia al refactoring, R√°pida retro alimentaci√≥, Mantenibilidad",
  createAt: "2020-10-24",
};

<small className="text--muted text--sm ml--6">2020-10-24</small>

# Los 4 pilares de una buena prueba unitaria

## Unit testing, principios, pr√°cticas y patrones | Resumen


En este post les voy a compartir 4 aspectos que definen lo que ser√≠a una prueba unitaria valiosa, veremos si es posible que exista una prueba unitaria ideal y por √∫ltimo revisaremos conceptos que nos van a ayudar a tener una buena suite de pruebas.

### ¬øQue hace buena a una prueba unitaria?
En post anteriores vimos que existen 3 caracter√≠sticas claves que hacen de una prueba unitaria una buena prueba unitaria:

* üíª Tienen que estar integadas en el ciclo de desarrollo.
* üí° Se debe probar solo las partes importantes.
* ü§î Deben proveer el mayor valor con el m√≠nimo costo de mantenimiento.

Si bien es f√°cil entender los primeros 2 puntos, es decir, tenemos que incluir pruebas unitarias cada que desarrollamos nuevas funcionalidades o corregimos bugs, y tambi√©n tenemos que probar solo las partes m√°s importantes de nuestro sistema, que suele ser la l√≥gica de negocio; nos falta saber **¬øC√≥mo hacer valiosa una prueba unitaria?**.

### Conociendo los 4 pilares de una buena prueba unitaria

Una prueba unitaria, tiene como pilares o fundamentos lo siguiente:

* üõ°Ô∏è Protecci√≥n contra las regresiones.
* üí™ Resistencia al refactoring.
* ‚ö° R√°pida retro alimentaci√≥n
* üî® Mantenibilidad

Estos cuatro pilares son fundamentales y se pueden utilizar dependiendo el grado que se tenga de cada uno para analizar cualquier tipo de prueba automatizada.

### Protecci√≥n contra las regresiones

Una **regresi√≥n** es un bug en el software, es cuando una funcionalidad deja de servir como se espera tr√°s una modificaci√≥n, usualmente cuando se agrega alguna caracter√≠stica nueva.

Una regresi√≥n es algo molesto, pero esto no es lo m√°s grave, si no que la realidad del software es que a mayor cantidad de nuevas caracter√≠sticas agregues, mayores las probabilidades de que aparezcan estos bugs o regresiones.

Un hecho de la programaci√≥n es que el c√≥digo no es un documento u objeto si no una responsabilidad.

Por todo lo anterior es que es crucial tener una buena protecci√≥n contra regresiones, pero: **¬øC√≥mo podemos saber si nuestras pruebas ofrecen una buena protecci√≥n contra regresiones?.** Para ello hay que tener en cuenta los siguientes puntos:

* üìù La cantidad de c√≥digo que se ejecuta durante la prueba
* üïπ La complejidad del c√≥digo que se est√° ejecutando
* üëì La significancia del c√≥digo ejecutado

Generalmente a mayor cantidad de c√≥digo de tu sistema es ejecutado en una prueba tiene mayor oportunidad de revelar una regresi√≥n, sin embargo, no solo es ejecutar c√≥digo por ejecutarlo, si no que tambi√©n entra en juego la complejidad del c√≥digo y la importancia que tenga para el problema que est√°s resolviendo.

```javascript
 class Animal {
  constructor(name, type, age) {
    this.name = name;
    this.type = type;
    this.age = age;
  }
  get name() { // ‚ö™Ô∏è Solo es un m√©todo con l√≥gica muy simple
    return this.name;
  }
  // ‚≠êÔ∏è Tiene m√°s significancia y m√°s complejidad para la clase Animal
  humanAge() { 
    if (this.type === "DOG") return this.age * 7;
    return this.age * 3;
  }
}
```

Por √∫ltimo es importante saber que todo el c√≥digo que no escribes como las librer√≠as o frameworks que utilizas tambi√©n cuenta y se debe incluir para esta protecci√≥n contra regresiones.

> Para maximizar la protecci√≥n contra regresiones, las pruebas deben ejecutar la mayor cantidad de c√≥digo posible tomando en cuenta la significancia que tiene para tu aplicaci√≥n.

### Resistencia al refactoring

El segundo pilar es la resistencia al refactoring, que es el grado que puede soportar una prueba tras haber ocurrido un refactoring del c√≥digo que est√° probando, sin que la prueba falle.

> **Refactoring**: Es modificar el c√≥digo existente sin alterar su comportamiento observado, estas modificaciones son para mejorar la calidad del c√≥digo, para que sea m√°s legible, simple, etc√©tera‚Ä¶

Supongamos que acabamos de hacer una nueva funcionalidad que esta trabajando correctamente, no rompe nada y las pruebas pasan, despu√©s de esto decidimos mejorar o limpiar el c√≥digo, tras hacerlo todo sigue funcionando a la perfecci√≥n, el c√≥digo se ve mejor, pero las pruebas comienzan a fallar üò±.

En el enunciado anterior vemos claramente lo que es la resistencia al refactoring en las pruebas, para ese ejemplo en espec√≠fico las pruebas no tuvieron resitencia al refactoring.

Cuando todo funciona bien y como se espera, pero las pruebas fallan, producen algo conocido como **falsos positivos**.

Como ya vimos, el objetivo de las pruebas unitarias es habilitar el crecimiento sostenible de un software, esto significa poder agregar nuevas caracter√≠sticas y refactorings de manera regular, reduciendo al m√≠nimo la introducci√≥n de bugs o regresiones.

La pruebas unitarias ofrecen una advertencia temprana de que se rompi√≥ algo y la confianza de agregar nuevas caracter√≠sticas sin introducir bugs; sin embargo, los mencionados **falsos positivos** diluyen estos beneficios:

* üíÄ Si las pruebas dan muchos falsos positivos se pierde la capacidad de reaccionar a los problemas leg√≠timos que sucedan, por que no sabr√°s si las pruebas estan fallando por una buena raz√≥n o no.
* üò™ Se pierde la confianza de agregar nuevas caracter√≠sitcas o refactorings por el temor que pueden infundir estas falsas alarmas, muchas veces los programadores prefieren no tocar el c√≥digo.

### ¬øQu√© produce los falsos positivos?

El n√∫mero de falsos positivos que genera una prueba est√° directamente relacionado con como est√° estructurada, si una prueba esta altamente acoplada con la implementaci√≥n del sistema bajo pruebas, mayor cantidad de falsos positivos tendr√°.

Por el contrario una prueba debe verificar el resultado final que el sistema bajo pruebas entrega, es decir, su comportamiento observable, y no los pasos o la implementaci√≥n que sigue para llegar a el.

Entendamos mejor con el siguiente ejemplo, est√° divido por pesta√±as, la primera es el sistema bajos pruebas: `rendermarkdown.js`, y en las siguientes pesta√±as son una manera incorrecta y una correcta de escribir la prueba:

`rendermarkdown.js`: Este es nuestro sistema bajo pruebas, es una clase que se encarga de crear un mensaje en markdown muy simple.
```javascript
// rendermarkdown.js üìÇ
class RenderMarkdown {
  renderTitle(message) {
    return `#${message}`;
  }
  renderSubtitle(message) {
    return `##${message}`;
  }
  renderParagraph(message) {
    return message;
  }
  render(message) {
    return (
      this.renderTitle(message) +
      " " +
      this.renderSubtitle(message) +
      " " +
      this.renderParagraph(message)
    );
  }
}
```

**bad test ‚ùå** : Esta es una manera incorrecta de estructurar la prueba por que estamos acoplando a la implementaci√≥n del m√©todo render en lugar del resultado final, aumentando mucho la probabilidad de falsos positivos y haciendo la prueba no resistente al refactoring.

```javascript
// BAD TEST ‚ùå
it("The markdown is generated correctly", () => {
  // Arrange
  const spyRenderTitle = jest.spyOn(RenderMarkdown.prototype, "renderTitle");
  const spyRenderSubtitle = jest.spyOn(
    RenderMarkdown.prototype,
    "renderSubtitle"
  );
  const spyRenderParagraph = jest.spyOn(
    RenderMarkdown.prototype,
    "renderParagraph"
  );
  const markdownRender = new MarkdownRender();
  // Act
  markdownRender.render("x");
  //Assert
  expect(spyRenderTitle).toHaveBeenCalled();
  expect(spyRenderSubtitle).toHaveBeenCalled();
  expect(spyRenderParagraph).toHaveBeenCalled();
});
```
¬øQue pasar√≠a si decidimos renombrar el m√©todo de `renderTitle` por `renderHeader`?: Nuestra prueba fallar√≠a al instante aunque el resultado final que es el mensaje en markdown no cambie, lo mismo si lo hacemos con los otros m√©todos.

**good test ‚úÖ** : A diferencia de la prueba anterior en esta se verifica el resultado(comportamiento) esperado del m√©todo render, as√≠ de esta manera no importan los cambios internos o refactorings que se le hagan a los pasos o al resto de m√©todos para llegar a el, siempre y cuando el resultado sea correcto.
  
```javascript
// GOOD TEST ‚úÖ
it("Render markdown message", () => {
  //Arrange
  const message = "x";
  const markdownRender = new MarkdownRender();
  // Act
  const markdownMessage = markdownRender.render(message)
  // Assert
  expect(markdownMessage).toBe('#x ##x x');
});
```
### La conexi√≥n entre los primeros 2 pilares y la precisi√≥n de las pruebas

Existe una conexi√≥n entre los 2 primeros pilares, la protecci√≥n contra regresiones y la resistencia al refactoring, ya que los dos determinan el nivel de presici√≥n de las pruebas.

Para entender mejor que es la presici√≥n en las pruebas unitarias, les comparto una tabla muy similar a la del libro y la explico a continuaci√≥n:

![Presici√≥n en las pruebas](/images/posts/tabla_presicio-pruebas.png)
<small>Presici√≥n en las pruebas</small>

‚úÖ Cuando tienes una funcionalidad correcta y adem√°s la prueba que lo verifica pasa, la prueba demuestra bien el estado del sistema, que en este caso no presenta bugs al estar funcionando correctamente.

‚úÖ Cuando la funcionalidad se rompe, y la prueba que lo verifica falla, se hace la detecci√≥n oportuna del bug o regresi√≥n, es decir, si nuestra funcionalidad deja de servir apropiadamente, se espera que la prueba falle.

Hasta ahora hemos explicados los dos condiciones correctas, si embargo como vemos en la tabla en rojo, hay dos situaciones incorrectas que bajan o quitan la presici√≥n de las pruebas.

‚ùå Cuando nuestra funcionalidad es correcta pero la prueba falla, obtenemos un **falso positivo**, suele suceder tras realizar un cambio al c√≥digo que no modifca el comportamiento observado (**refactorign**), aqu√≠ es donde nos ayuda el pilar de **resistencia al refactoring**.

‚ùå Cuando la funcionalidad esta rota pero la prueba pasa, es un falso negativo, quiere decir que la prueba no es capaz de detectar el mal funcionamiento o bug, desproveyendonos de la protecci√≥n contra regresiones.

En conclusi√≥n, la presici√≥n de una prueba esta determinada por :

* ‚öôÔ∏è Que tan buena es la prueba de indicar la presencia de bugs (ausencia de falsos negativos ‚Äì protecci√≥n contra regresesions).
* ‚öôÔ∏è Que tan buena es la prueba de indicar la ausencia de bugs(ausencia de falsos positvos ‚Äì resistencia al refactorign)

Podr√≠a parecer que los falsos negativos, son los peores, sin embargo a la larga, los falsos positivos demeritan totalmente las bondades que puede tener una suite de pruebas.

### Los √∫ltimos pilares: r√°pida retro alimentaci√≥n y la mantenibilidad

Los dos pilares restantes son dos caracter√≠sticas de las que ya hemos hablado, la r√°pida retro alimentaci√≥n y la mantenibilidad, para medirlas se nesecita considerar lo siguiente:

* üî® **Mantenibilidad**: que tan f√°cil son de entender las pruebas, generalmente a menor cantidad de l√≠neas tengan es m√°s f√°cil de entender, pero esto no significa que debamos reducir nuestas pruebas de una manera forzada, hay que tratar las pruebas como lo que son, algo importante.
* ‚ö°Ô∏è **R√°pida retro alimentaci√≥**n: Que tan df√≠cil es correr las pruebas, aqu√≠ influyen factores como el tiempo de espera para ver los resultados, si tienes que levantar x o y instancia, etc√©tera.

La r√°pida retro alimentaci√≥n es importante por que puede alentar o desanimar el que ejecutes las pruebas, a si mismo, la mantebilidad en las pruebas nos ayuda a estar teniendo una suite de pruebas sana de manera f√°cil.

### ¬øExiste la prueba ideal?

La respuesta corta es **NO**, porque siempre va existir un trade off entre los pilares de : protecci√≥n contra regresiones, resistencia al refactoring y la r√°pida retro alimentaci√≥n.

Cuando realizamos una prueba siempre se va a sacrificar algo de uno de los 3 pilares mencionados, el pilar de la mantenibilidad no est√° correlacionado con los anteriores.

Para entender mejor esto veamos la siguiente lista de ejemplos:

* üìù En una pruebna end-to-end se ejecutagran cantidad de c√≥digo ya que se verifica desde el m√°s bajo nivel hasta lo que se le presenta al usuario, por lo cual ofrecen una gran protecci√≥n contra regresiones, pero el hecho de abarcar varios m√≥dulos hace que tengan una lenta retro alimentaci√≥n.
* üç∑ Otro caso es cuando haces una prueba unitaria fr√°gil, es decir, muy acoplada a la implementaci√≥n dejando de lado la resistencia al refactorign, pero teniendo una buena protecci√≥n contra regresiones ya que detectar√° de inmediato un bug.
* üçû Por √∫ltimo otro caso es cuando realizas pruebas triviales, cuando pruebas comportamientos extreamandamente simples, son pruebas altamente r√°pidas y resistentes al refactorign pero no proveen ninguna protecci√≥n.

Para el caso de las pruebas unitarias la resistencia al refactorign no es negociable, se tiene o no se tiene, por ello, con lo que se tiene que jugar es entre la protecci√≥n contra regresiones y la r√°pida retro alimentaci√≥n.

![Diagrama de venn pilares en las pruebas](/images/posts/venn-4-pilares.png)
<small>Diagrama de venn de:  pilares de las pruebas unitarias</small>

> En mi punto de vista personal creo que lo mejor es tener el m√°ximo de protecci√≥n posible trantando de disminuir lo menor posible la r√°pida retro alimentaci√≥n.

Conceptos de automatizaci√≥n
Hablar√© solo de dos conceptos de automatizaci√≥n de manera breve: las pruebas de caja negra y las pruebas de caja blanca:

* ‚¨úÔ∏è Las pruebas de caja blanca verifican la aplicaci√≥n internamente, es decir, se realizan tomando el cuenta el c√≥digo y la implementaci√≥n, se enfocan en como lo hace.
* ‚¨õÔ∏è Las pruebas de caja negra verifican el resultado esperado o lo que se supone que la aplicaci√≥n tiene que hacer sin tomar en cuenta el como lo hace o la implementaci√≥n.

Podemos darnos cuenta que las pruebas de caja blanca nos van a quitar la resistencia al refactoring y que debemos tomar por defecto la caja negra como m√©todo para realizar nuestras pruebas unitarias, sin embargo, todav√≠a se puede utilizar el m√©todo de caja blanca para analizar las pruebas y otras m√©tricas.

Por ejemplo cuando estamos analizando el code coverage o branch coverage es necesario conocer como esta implementada la aplicaci√≥n, incluso tambi√©n la caja blanca nos sirve para analizar el como se comporta una pieza de la aplicaci√≥n para determinar el resultado esperado.

Lo mejor es utilizar una combinaci√≥n de ambos m√©todos.

Entrar√© en m√°s detalle en pr√≥ximos cap√≠tulos de este post que es un resumen y mi entendimiento del libro: 

[üìñ Unit testing: principles, pratices and patterns‚Äù por Vladimir Khorikov de la editorial Manning](https://www.manning.com/books/unit-testing).
